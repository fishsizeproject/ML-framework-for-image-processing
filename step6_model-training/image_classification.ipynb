{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb7qyhNL1yWt"
      },
      "source": [
        "# Image classification with TensorFlow Lite Model Maker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m86-Nh4pMHqY"
      },
      "source": [
        "The [TensorFlow Lite Model Maker library](https://www.tensorflow.org/lite/guide/model_maker) simplifies the process of adapting and converting a TensorFlow neural-network model to particular input data when deploying this model for on-device ML applications.\n",
        "\n",
        "This notebook shows an end-to-end example that utilizes this Model Maker library to illustrate the adaption and conversion of a commonly-used image classification model to classify flowers on a mobile device."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcLF2PKkSbV3"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "To run this example, we first need to install several required packages, including Model Maker package that in GitHub [repo](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSrC8sz13_xd",
        "outputId": "add6e9c2-2574-4874-85e9-c4171708e23a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libportaudio2 is already the newest version (19.6.0-1).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libnvidia-common-460 nsight-compute-2020.2.0\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 70 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt -y install libportaudio2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cv3K3oaksJv",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!pip install -q tflite-model-maker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx1HGRoFQ54j"
      },
      "source": [
        "Import the required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtxiUeZEiXpt",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import image_classifier\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker.config import QuantizationConfig\n",
        "from tflite_model_maker.image_classifier import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCykEcC_Ejue",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f0lNSpREoO_",
        "outputId": "ea9411a8-572c-4fc7-c9ae-636a5bb4452e",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating gs://fish_size_project_data/...\n",
            "ServiceException: 409 A Cloud Storage bucket named 'fish_size_project_data' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
          ]
        }
      ],
      "source": [
        "BUCKET_NAME = 'project_name'\n",
        "\n",
        "GCS_BUCKET = f'gs://{BUCKET_NAME}'\n",
        "!gsutil mb -p $GCP_PROJECT_ID $GCS_BUCKET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg4cBqw4EoRY",
        "outputId": "c5d5501b-9d3d-4527-bc43-12e4a4a0e74c",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2537  100  2537    0     0  60404      0 --:--:-- --:--:-- --:--:-- 60404\n",
            "OK\n",
            "70 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "gcsfuse is already the newest version (0.41.1).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libnvidia-common-460 nsight-compute-2020.2.0\n",
            "Use 'apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 70 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# install gcsfuse on colab.\n",
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YN3m56SEr_4",
        "outputId": "056ac425-11c4-4be4-9f4c-be8dfacb1849",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘deeper_data’: File exists\n",
            "2022/05/16 09:08:18.569588 Start gcsfuse/0.41.1 (Go version go1.17.6) for app \"\" using mount point: /content/deeper_data\n",
            "2022/05/16 09:08:18.585287 Opening GCS connection...\n",
            "2022/05/16 09:08:18.743761 Mounting file system \"fish_size_project_data\"...\n",
            "2022/05/16 09:08:18.744297 File system has been successfully mounted.\n"
          ]
        }
      ],
      "source": [
        "!mkdir deeper_data\n",
        "!gcsfuse --implicit-dirs fish_size_project_data deeper_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1QG32ivs9lF"
      },
      "source": [
        "## Model training and testing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygEncJxtl-nQ"
      },
      "source": [
        "### Step 1: Load Input Data Specific\n",
        "\n",
        "The dataset should have the following directory structure:\n",
        "\n",
        "<pre>\n",
        "<b>fish_photos</b>\n",
        "|__ <b>Abramis brama</b>\n",
        "    |______ 100080576_f52e8ee070_n.jpg\n",
        "    |______ 14167534527_781ceb1b7a_n.jpg\n",
        "    |______ ...\n",
        "|__ <b>Cyprinus carpio</b>\n",
        "    |______ 10043234166_e6dd915111_n.jpg\n",
        "    |______ 1426682852_e62169221f_m.jpg\n",
        "    |______ ...\n",
        "|__ <b>Esox lucius</b>\n",
        "    |______ 102501987_3cdb8e5394_n.jpg\n",
        "    |______ 14982802401_a3dfb22afb.jpg\n",
        "    |______ ...\n",
        "|__ <b>Micropterus salmoides</b>\n",
        "    |______ 12471791574_bb1be83df4.jpg\n",
        "    |______ 15122112402_cafa41934f.jpg\n",
        "    |______ ...\n",
        "|__ <b>Perca fluviatilis</b>\n",
        "    |______ 13976522214_ccec508fe7.jpg\n",
        "    |______ 14487943607_651e8062a1_m.jpg\n",
        "    |______ ...\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNRNv_mloS89"
      },
      "source": [
        "If you prefer not to upload your images to the cloud, you could try to run the library locally following the [guide](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker) in GitHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfzyAvk7Et_c",
        "outputId": "08edb266-2c5a-41e6-f8e8-8a10b8b7cfdb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/deeper_data/MonthlyDeeperData/2021-08-01/images\n"
          ]
        }
      ],
      "source": [
        "cd deeper_data/annotated_images_pilot_by_spp_augmented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPlR7pbnEUT4",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "image_path = './'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E051HBUM5owi"
      },
      "source": [
        "Use `DataLoader` class to load data.\n",
        "\n",
        "As for `from_folder()` method, it could load data from the folder. It assumes that the image data of the same class are in the same subdirectory and the subfolder name is the class name. Currently, JPEG-encoded images and PNG-encoded images are supported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_fOlZsklmlL",
        "outputId": "88b1bdf2-08ff-4878-badd-2146a5ab4edc",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Load image with size: 4809, num_label: 6, labels: Abramis brama, Cyprinus carpio, Esox lucius, Micropterus salmoides, Perca fluviatilis, Sander lucioperca.\n"
          ]
        }
      ],
      "source": [
        "data = DataLoader.from_folder(image_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u501eT4koURB"
      },
      "source": [
        "Split it to training data (80%), validation data (10%, optional) and testing data (10%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cY4UU5SUobtJ",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "train_data, rest_data = data.split(0.8)\n",
        "validation_data, test_data = rest_data.split(0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9_MYPie3EMO"
      },
      "source": [
        "Show 25 image examples with labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ih4Wx44I482b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(25,25))\n",
        "for i, (image, label) in enumerate(data.gen_dataset().unbatch().take(25)):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image.numpy(), cmap=plt.cm.gray)\n",
        "  plt.xlabel(data.index_to_label[label.numpy()])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWuoensX4vDA"
      },
      "source": [
        "### Step 2: Customize the TensorFlow Model\n",
        "\n",
        "Currently, Tensorflow Lite support several models such as  EfficientNet-Lite* models, MobileNetV2, ResNet50 as pre-trained models for image classification. But it is very flexible to add new pre-trained models to this library with just a few lines of code.\n",
        "\n",
        "\n",
        "The following walks through this end-to-end example step by step to show more detail.\n",
        "\n",
        "Create a custom image classifier model based on the loaded data. The default model is EfficientNet-Lite0.\n",
        "\n",
        "\n",
        "**Other models**\n",
        "\n",
        "This library supports EfficientNet-Lite models only. For MobileNetV2 and ResNet50 need to use other libraries. EfficientNet-Lite are a family of image classification models that could achieve state-of-art accuracy and suitable for Edge devices. The default model is EfficientNet-Lite0.\n",
        "\n",
        "We could switch model to MobileNetV2 by just setting parameter model_spec to the MobileNetV2 model specification in create method.\n",
        "\n",
        "List of models names:\n",
        "\n",
        "| Model architecture |\n",
        "|--------------------|\n",
        "| mobilenet_v2 |\n",
        "| efficientnet_lite0 |\n",
        "| resnet_50 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M9bn703AHt2"
      },
      "source": [
        "**Change the training hyperparameters**\n",
        "\n",
        "We could also change the training hyperparameters like `epochs`, `dropout_rate` and `batch_size` that could affect the model accuracy. The model parameters you can adjust are:\n",
        "\n",
        "\n",
        "*   `epochs`: more epochs could achieve better accuracy until it converges but training for too many epochs may lead to overfitting.\n",
        "*   `dropout_rate`: The rate for dropout, avoid overfitting. None by default.\n",
        "*   `batch_size`: number of samples to use in one training step.  None by default.\n",
        "*   `validation_data`: Validation data. If None, skips validation process. None by default.\n",
        "*   `train_whole_model`: If true, the Hub module is trained together with the classification layer on top. Otherwise, only train the top classification layer. None by default.\n",
        "*   `learning_rate`: Base learning rate. None by default.\n",
        "*   `momentum`: a Python float forwarded to the optimizer. Only used when\n",
        "      `use_hub_library` is True. None by default.\n",
        "*   `shuffle`: Boolean, whether the data should be shuffled. False by default.\n",
        "*   `use_augmentation`: Boolean, use data augmentation for preprocessing. False by default.\n",
        "*   `use_hub_library`: Boolean, use `make_image_classifier_lib` from tensorflow hub to retrain the model. This training pipeline could achieve better performance for complicated dataset with many categories. True by default. \n",
        "*   `warmup_steps`: Number of warmup steps for warmup schedule on learning rate. If None, the default warmup_steps is used which is the total training steps in two epochs. Only used when `use_hub_library` is False. None by default.\n",
        "*   `model_dir`: Optional, the location of the model checkpoint files. Only used when `use_hub_library` is False. None by default.\n",
        "\n",
        "Parameters which are None by default like `epochs` will get the concrete default parameters in [make_image_classifier_lib](https://github.com/tensorflow/hub/blob/02ab9b7d3455e99e97abecf43c5d598a5528e20c/tensorflow_hub/tools/make_image_classifier/make_image_classifier_lib.py#L54) from TensorFlow Hub library or  [train_image_classifier_lib](https://github.com/tensorflow/examples/blob/f0260433d133fd3cea4a920d1e53ecda07163aee/tensorflow_examples/lite/model_maker/core/task/train_image_classifier_lib.py#L61).\n",
        "\n",
        "For example, we could train with more epochs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNDBP2qA54aK"
      },
      "source": [
        "\n",
        "\n",
        "The **`create` function** is the critical part of this library. It uses transfer learning with a pretrained model similar to the [tutorial](https://www.tensorflow.org/tutorials/images/transfer_learning).\n",
        "\n",
        "The `create` function contains the following steps:\n",
        "\n",
        "1.   Split the data into training, validation, testing data according to parameter `validation_ratio` and `test_ratio`. The default value of `validation_ratio` and `test_ratio` are `0.1` and `0.1`.\n",
        "2.   Download a [Image Feature Vector](https://www.tensorflow.org/hub/common_signatures/images#image_feature_vector) as the base model from TensorFlow Hub. The default pre-trained model is  EfficientNet-Lite0.\n",
        "3.   Add a classifier head with a Dropout Layer with `dropout_rate` between head layer and pre-trained model. The default `dropout_rate` is the default `dropout_rate` value from [make_image_classifier_lib](https://github.com/tensorflow/hub/blob/master/tensorflow_hub/tools/make_image_classifier/make_image_classifier_lib.py#L55) by TensorFlow Hub.\n",
        "4.   Preprocess the raw input data. Currently, preprocessing steps including normalizing the value of each image pixel to model input scale and resizing it to model input size.   EfficientNet-Lite0 have the input scale `[0, 1]` and the input image size `[224, 224, 3]`.\n",
        "5.   Feed the data into the classifier model. By default, the training parameters such as training epochs, batch size, learning rate, momentum are the default values from [make_image_classifier_lib](https://github.com/tensorflow/hub/blob/master/tensorflow_hub/tools/make_image_classifier/make_image_classifier_lib.py#L55) by TensorFlow Hub. Only the classifier head is trained.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvYSUuJY3QxR",
        "outputId": "987f5063-ecfc-4cb9-858e-7c784e0cf851",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Retraining the models...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hub_keras_layer_v1v2 (HubKe  (None, 1280)             3413024   \n",
            " rasLayerV1V2)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 7686      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,420,710\n",
            "Trainable params: 7,686\n",
            "Non-trainable params: 3,413,024\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "120/120 [==============================] - 502s 4s/step - loss: 1.1627 - accuracy: 0.6531 - val_loss: 0.8766 - val_accuracy: 0.8212\n",
            "Epoch 2/20\n",
            "120/120 [==============================] - 338s 3s/step - loss: 0.8724 - accuracy: 0.8042 - val_loss: 0.8041 - val_accuracy: 0.8628\n",
            "Epoch 3/20\n",
            "120/120 [==============================] - 313s 3s/step - loss: 0.8062 - accuracy: 0.8398 - val_loss: 0.7729 - val_accuracy: 0.8773\n",
            "Epoch 4/20\n",
            "120/120 [==============================] - 340s 3s/step - loss: 0.7751 - accuracy: 0.8578 - val_loss: 0.7490 - val_accuracy: 0.9023\n",
            "Epoch 5/20\n",
            "120/120 [==============================] - 332s 3s/step - loss: 0.7511 - accuracy: 0.8753 - val_loss: 0.7340 - val_accuracy: 0.9002\n",
            "Epoch 6/20\n",
            "120/120 [==============================] - 335s 3s/step - loss: 0.7348 - accuracy: 0.8841 - val_loss: 0.7278 - val_accuracy: 0.9023\n",
            "Epoch 7/20\n",
            "120/120 [==============================] - 305s 3s/step - loss: 0.7197 - accuracy: 0.8898 - val_loss: 0.7159 - val_accuracy: 0.9085\n",
            "Epoch 8/20\n",
            "120/120 [==============================] - 315s 3s/step - loss: 0.7055 - accuracy: 0.9034 - val_loss: 0.7118 - val_accuracy: 0.9064\n",
            "Epoch 9/20\n",
            "120/120 [==============================] - 307s 3s/step - loss: 0.6972 - accuracy: 0.9086 - val_loss: 0.7039 - val_accuracy: 0.9168\n",
            "Epoch 10/20\n",
            "120/120 [==============================] - 322s 3s/step - loss: 0.6924 - accuracy: 0.9102 - val_loss: 0.6983 - val_accuracy: 0.9168\n",
            "Epoch 11/20\n",
            "120/120 [==============================] - 340s 3s/step - loss: 0.6872 - accuracy: 0.9094 - val_loss: 0.6924 - val_accuracy: 0.9148\n",
            "Epoch 12/20\n",
            "120/120 [==============================] - 351s 3s/step - loss: 0.6716 - accuracy: 0.9255 - val_loss: 0.6899 - val_accuracy: 0.9127\n",
            "Epoch 13/20\n",
            "120/120 [==============================] - 355s 3s/step - loss: 0.6768 - accuracy: 0.9161 - val_loss: 0.6920 - val_accuracy: 0.9168\n",
            "Epoch 14/20\n",
            "120/120 [==============================] - 344s 3s/step - loss: 0.6707 - accuracy: 0.9234 - val_loss: 0.6880 - val_accuracy: 0.9168\n",
            "Epoch 15/20\n",
            "120/120 [==============================] - 405s 3s/step - loss: 0.6653 - accuracy: 0.9201 - val_loss: 0.6855 - val_accuracy: 0.9127\n",
            "Epoch 16/20\n",
            "120/120 [==============================] - 349s 3s/step - loss: 0.6676 - accuracy: 0.9242 - val_loss: 0.6833 - val_accuracy: 0.9168\n",
            "Epoch 17/20\n",
            "120/120 [==============================] - 349s 3s/step - loss: 0.6575 - accuracy: 0.9268 - val_loss: 0.6810 - val_accuracy: 0.9189\n",
            "Epoch 18/20\n",
            "120/120 [==============================] - 322s 3s/step - loss: 0.6572 - accuracy: 0.9352 - val_loss: 0.6741 - val_accuracy: 0.9231\n",
            "Epoch 19/20\n",
            "120/120 [==============================] - 341s 3s/step - loss: 0.6523 - accuracy: 0.9331 - val_loss: 0.6783 - val_accuracy: 0.9189\n",
            "Epoch 20/20\n",
            "120/120 [==============================] - 338s 3s/step - loss: 0.6509 - accuracy: 0.9331 - val_loss: 0.6759 - val_accuracy: 0.9210\n"
          ]
        }
      ],
      "source": [
        "# model = image_classifier.create(train_data, validation_data=validation_data)\n",
        "model = image_classifier.create(train_data, model_spec=model_spec.get('efficientnet_lite0'), validation_data=validation_data, batch_size=32, epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JFOKWnH9x8_"
      },
      "source": [
        "Have a look at the detailed model structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNXAfjl192dC",
        "outputId": "33169e1c-1df5-41d3-ede6-ae5fd6592bd7",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hub_keras_layer_v1v2 (HubKe  (None, 1280)             3413024   \n",
            " rasLayerV1V2)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 7686      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,420,710\n",
            "Trainable params: 7,686\n",
            "Non-trainable params: 3,413,024\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP5FPk_tOxoZ"
      },
      "source": [
        "### Step 3: Evaluate the Customized Model\n",
        "\n",
        "Evaluate the result of the model, get the loss and accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8c2ZQ0J3Riy",
        "outputId": "192c6768-a231-4589-8f99-c4ca16e0628a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 147s 3s/step - loss: 0.7073 - accuracy: 0.9064\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZCrYOWoCt05"
      },
      "source": [
        "We could plot the predicted results in 100 test images. Predicted labels with red color are the wrong predicted results while others are correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9O9Kx7nDQWD",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# A helper function that returns 'red'/'black' depending on if its two input\n",
        "# parameter matches or not.\n",
        "def get_label_color(val1, val2):\n",
        "  if val1 == val2:\n",
        "    return 'black'\n",
        "  else:\n",
        "    return 'red'\n",
        "\n",
        "# Then plot 100 test images and their predicted labels.\n",
        "# If a prediction result is different from the label provided label in \"test\"\n",
        "# dataset, we will highlight it in red color.\n",
        "plt.figure(figsize=(40, 40))\n",
        "predicts = model.predict_top_k(test_data)\n",
        "for i, (image, label) in enumerate(test_data.gen_dataset().unbatch().take(100)):\n",
        "  ax = plt.subplot(10, 10, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image.numpy(), cmap=plt.cm.gray)\n",
        "\n",
        "  predict_label = predicts[i][0][0]\n",
        "  color = get_label_color(predict_label,\n",
        "                          test_data.index_to_label[label.numpy()])\n",
        "  ax.xaxis.label.set_color(color)\n",
        "  plt.xlabel('Predicted: %s' % predict_label)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6FVfTCIXbKU",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Import pandas library\n",
        "import pandas as pd\n",
        "\n",
        "# predicts = model.predict_top_k(test_data)\n",
        "appended_data = []\n",
        "\n",
        "for i, (image, label) in enumerate(test_data.gen_dataset().unbatch().take(100)):\n",
        "  predicted_label = predicts[i][0][0]\n",
        "  # expected_label = test_data.index_to_label[label.numpy()]\n",
        "  # store DataFrame in list\n",
        "  appended_data.append(predicted_label)\n",
        "  # appended_data.append(expected_label)\n",
        "\n",
        "df_predicted = pd.DataFrame(appended_data, columns = ['predicted'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "UJRfstyky48n",
        "outputId": "dcc4daeb-0481-4087-8381-7aa49ef4cd02",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# predicts = model.predict_top_k(test_data)\n",
        "appended_data = []\n",
        "\n",
        "for i, (image, label) in enumerate(test_data.gen_dataset().unbatch().take(100)):\n",
        "  # predicted_label = predicts[i][0][0]\n",
        "  expected_label = test_data.index_to_label[label.numpy()]\n",
        "  # store DataFrame in list\n",
        "  # appended_data.append(predicted_label)\n",
        "  appended_data.append(expected_label)\n",
        "\n",
        "df_expected = pd.DataFrame(appended_data, columns = ['expected'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "EL9tkLgPzEhF",
        "outputId": "bfde1441-a519-4895-8aa6-162d8fa5118b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e14655ca-f7fd-48b5-bd87-d6fac7a081b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted</th>\n",
              "      <th>expected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Esox lucius</td>\n",
              "      <td>Esox lucius</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cyprinus carpio</td>\n",
              "      <td>Cyprinus carpio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Perca fluviatilis</td>\n",
              "      <td>Perca fluviatilis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abramis brama</td>\n",
              "      <td>Abramis brama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Esox lucius</td>\n",
              "      <td>Esox lucius</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Perca fluviatilis</td>\n",
              "      <td>Perca fluviatilis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Perca fluviatilis</td>\n",
              "      <td>Perca fluviatilis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Esox lucius</td>\n",
              "      <td>Esox lucius</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Cyprinus carpio</td>\n",
              "      <td>Cyprinus carpio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Perca fluviatilis</td>\n",
              "      <td>Perca fluviatilis</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e14655ca-f7fd-48b5-bd87-d6fac7a081b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e14655ca-f7fd-48b5-bd87-d6fac7a081b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e14655ca-f7fd-48b5-bd87-d6fac7a081b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            predicted           expected\n",
              "0         Esox lucius        Esox lucius\n",
              "1     Cyprinus carpio    Cyprinus carpio\n",
              "2   Perca fluviatilis  Perca fluviatilis\n",
              "3       Abramis brama      Abramis brama\n",
              "4         Esox lucius        Esox lucius\n",
              "..                ...                ...\n",
              "95  Perca fluviatilis  Perca fluviatilis\n",
              "96  Perca fluviatilis  Perca fluviatilis\n",
              "97        Esox lucius        Esox lucius\n",
              "98    Cyprinus carpio    Cyprinus carpio\n",
              "99  Perca fluviatilis  Perca fluviatilis\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_confusion = pd.concat([df_predicted, df_expected], axis=1)\n",
        "df_confusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2V2AVxBIOSH",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "df_confusion.to_csv(\"../../df_confusion.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2S-dMO5LS2V",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "df_prob_predicts = pd.DataFrame(predicts)\n",
        "df_prob_predicts.to_csv(\"../../df_prob_predicts.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3H0rkbLUZAG"
      },
      "source": [
        "If the accuracy doesn't meet the app requirement, one could refer to [Advanced Usage](#scrollTo=zNDBP2qA54aK) to explore alternatives such as changing to a larger model, adjusting re-training parameters etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bcSVPZ9SMH_"
      },
      "source": [
        "### Step 4: Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jdMLYwJqMVKG",
        "outputId": "95684cf9-73c2-4fd7-c5e1-b8d118ef1a12",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-21f1030a-2e11-4872-b40c-a75b2203ade3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>predicted</th>\n",
              "      <th>expected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Esox lucius</td>\n",
              "      <td>Esox lucius</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Cyprinus carpio</td>\n",
              "      <td>Cyprinus carpio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Perca fluviatilis</td>\n",
              "      <td>Perca fluviatilis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Abramis brama</td>\n",
              "      <td>Abramis brama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Esox lucius</td>\n",
              "      <td>Esox lucius</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21f1030a-2e11-4872-b40c-a75b2203ade3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-21f1030a-2e11-4872-b40c-a75b2203ade3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-21f1030a-2e11-4872-b40c-a75b2203ade3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0          predicted           expected\n",
              "0           0        Esox lucius        Esox lucius\n",
              "1           1    Cyprinus carpio    Cyprinus carpio\n",
              "2           2  Perca fluviatilis  Perca fluviatilis\n",
              "3           3      Abramis brama      Abramis brama\n",
              "4           4        Esox lucius        Esox lucius"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df_confusion = pd.read_csv(\"../../df_confusion.csv\", index_col=False)\n",
        "df_confusion.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "miGv2gh9TYPx",
        "outputId": "ec4cdfb0-511f-4350-9a58-e7adb53f8625",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-30eba76f-7c6e-49c4-8ce7-a0854edf1e4a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted</th>\n",
              "      <th>N. of predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Esox lucius</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cyprinus carpio</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Perca fluviatilis</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Micropterus salmoides</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sander lucioperca</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Abramis brama</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30eba76f-7c6e-49c4-8ce7-a0854edf1e4a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-30eba76f-7c6e-49c4-8ce7-a0854edf1e4a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-30eba76f-7c6e-49c4-8ce7-a0854edf1e4a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "               predicted  N. of predicted\n",
              "0            Esox lucius               29\n",
              "1        Cyprinus carpio               25\n",
              "2      Perca fluviatilis               21\n",
              "3  Micropterus salmoides               11\n",
              "4      Sander lucioperca                8\n",
              "5          Abramis brama                6"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1 = df_confusion['predicted'].value_counts().rename_axis('predicted').reset_index(name='N. of predicted')\n",
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "VKUg9YqoVycs",
        "outputId": "c8921d9c-a5f2-4644-db42-1450142c04ec",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ef099ae8-edd6-41c8-b7d8-5cb76588bb74\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>expected</th>\n",
              "      <th>N. of expected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Esox lucius</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cyprinus carpio</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Perca fluviatilis</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Micropterus salmoides</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sander lucioperca</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Abramis brama</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef099ae8-edd6-41c8-b7d8-5cb76588bb74')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef099ae8-edd6-41c8-b7d8-5cb76588bb74 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef099ae8-edd6-41c8-b7d8-5cb76588bb74');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                expected  N. of expected\n",
              "0            Esox lucius              29\n",
              "1        Cyprinus carpio              24\n",
              "2      Perca fluviatilis              21\n",
              "3  Micropterus salmoides              11\n",
              "4      Sander lucioperca               9\n",
              "5          Abramis brama               6"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2 = df_confusion['expected'].value_counts().rename_axis('expected').reset_index(name='N. of expected')\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CFAZdGhONrE",
        "outputId": "33de6099-b789-48f2-ec23-2cd5e66daf6b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 5,  0,  0,  0,  1,  0],\n",
              "       [ 0, 24,  0,  0,  0,  0],\n",
              "       [ 0,  0, 27,  0,  1,  1],\n",
              "       [ 0,  0,  0, 11,  0,  0],\n",
              "       [ 0,  1,  0,  0, 18,  2],\n",
              "       [ 1,  0,  2,  0,  1,  5]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(df_confusion[\"expected\"], df_confusion[\"predicted\"])\n",
        "confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXw2ng9N7XFB",
        "outputId": "9b0a11f4-9c89-4abc-b34b-7834493879ef",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusion_matrix.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_mypKxLSHHt",
        "outputId": "8f55b8a5-a2bc-421c-d4d4-6b6c8d46d559",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.83333333, 0.        , 0.        , 0.        , 0.16666667,\n",
              "        0.        ],\n",
              "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.93103448, 0.        , 0.03448276,\n",
              "        0.03448276],\n",
              "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.04761905, 0.        , 0.        , 0.85714286,\n",
              "        0.0952381 ],\n",
              "       [0.11111111, 0.        , 0.22222222, 0.        , 0.11111111,\n",
              "        0.55555556]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusion_normalized = confusion_matrix.astype(\"float\") / confusion_matrix.sum(axis=1)[:,None]\n",
        "confusion_normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "q0JIiRnNZEme",
        "outputId": "31b0b5ad-47a4-4e03-b0ae-c2b2e845cba5",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 15.0, 'Predicted label')"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "axis_labels = [\"Abramis brama\", \"Cyprinus carpio\", \"Esox lucius\", \"Micropterus salmoides\", \"Perca fluviatilis\", \"Sander lucioperca\"]\n",
        "ax = sns.heatmap(confusion_normalized, xticklabels=axis_labels, yticklabels=axis_labels,\n",
        "                 cmap='Blues', annot=True, fmt='.2f', square=True)\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.ylabel(\"True label\")\n",
        "plt.xlabel(\"Predicted label\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeHoGAceO2xV"
      },
      "source": [
        "### Step 5: Export to TensorFlow Lite Model\n",
        "\n",
        "Convert the trained model to TensorFlow Lite model format with [metadata](https://www.tensorflow.org/lite/convert/metadata) so that you can later use in an on-device ML application. The label file and the vocab file are embedded in metadata. The default TFLite filename is `model.tflite`.\n",
        "\n",
        "In many on-device ML application, the model size is an important factor. Therefore, it is recommended that you apply quantize the model to make it smaller and potentially run faster.\n",
        "The default post-training quantization technique is full integer quantization for the image classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeMBF-g0Jior",
        "outputId": "048401e6-5d5f-4dfb-efd1-d6ca840fd045",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpjfdocx4x/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpjfdocx4x/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving labels in /tmp/tmpn01xoqeb/labels.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving labels in /tmp/tmpn01xoqeb/labels.txt\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:TensorFlow Lite model exported successfully: ../../model_efficientnet_batch32_epochs20.tflite\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:TensorFlow Lite model exported successfully: ../../model_efficientnet_batch32_epochs20.tflite\n"
          ]
        }
      ],
      "source": [
        "model.export(export_dir='../../', tflite_filename='model_efficientnet_batch32_epochs20.tflite')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROS2Ay2jMPCl"
      },
      "source": [
        "See [example applications and guides of image classification](https://www.tensorflow.org/lite/models/image_classification/overview#example_applications_and_guides) for more details about how to integrate the TensorFlow Lite model into mobile apps.\n",
        "\n",
        "This model can be integrated into an Android or an iOS app using the [ImageClassifier API](https://www.tensorflow.org/lite/inference_with_metadata/task_library/image_classifier) of the [TensorFlow Lite Task Library](https://www.tensorflow.org/lite/inference_with_metadata/task_library/overview)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "habFnvRxxQ4A"
      },
      "source": [
        "The allowed export formats can be one or a list of the following:\n",
        "\n",
        "*   `ExportFormat.TFLITE`\n",
        "*   `ExportFormat.LABEL`\n",
        "*   `ExportFormat.SAVED_MODEL`\n",
        "\n",
        "By default, it just exports TensorFlow Lite model with metadata. You can also selectively export different files. For instance, exporting only the label file as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ah0WpqRmRLEO",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# model.export(export_dir='.', export_format=ExportFormat.LABEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zR0YiA3JjK5"
      },
      "source": [
        "# Load the saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kF1BVZcYHW4l",
        "outputId": "f4a52c16-d5de-440b-e46e-2f782e65c18a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdeeper_data\u001b[0m/  model_efficientnet_batch32_epochs20.tflite  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDf78Zl-OZsj",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "tflite_model_file = '/content/model_efficientnet_batch32_epochs20.tflite'\n",
        "\n",
        "# Then we can load and test it like this:\n",
        "\n",
        "# Load TFLite model and allocate tensors.\n",
        "with open(tflite_model_file, 'rb') as fid:\n",
        "    tflite_model = fid.read()\n",
        "    \n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAh5OET14djW",
        "outputId": "f35b6bbc-54e3-4034-843a-ddd0beb44f19",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.lite.python.interpreter.Interpreter at 0x7efde1524f50>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "interpreter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3XfkEzn44Pr"
      },
      "source": [
        "## Run inference on set of images\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Lez-qwaUrcb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from tflite_support.task import vision\n",
        "from tflite_support.task import core\n",
        "from tflite_support.task import processor\n",
        "\n",
        "# Initialization\n",
        "base_options = core.BaseOptions(file_name=tflite_model_file)\n",
        "classification_options = processor.ClassificationOptions(max_results=1)\n",
        "options = vision.ImageClassifierOptions(base_options=base_options, classification_options=classification_options)\n",
        "classifier = vision.ImageClassifier.create_from_options(options)\n",
        "\n",
        "# Alternatively, you can create an image classifier in the following manner:\n",
        "# classifier = vision.ImageClassifier.create_from_file(tflite_model_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEpf6Mf65XX5",
        "outputId": "b481bd9f-e8d8-4fe8-b9a1-1c2bec691b87",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/deeper_data/MonthlyDeeperData/2021-08-01/images\n"
          ]
        }
      ],
      "source": [
        "cd deeper_data/MonthlyDeeperData/2021-08-01/images/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEEHozZDTThV",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "image_path1 = '001eb843-13e5-4531-b1a2-b11ac00a9b57.png'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3jTseZATg6U",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "img = mpimg.imread(image_path1)\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nINXaCSb5Vpa",
        "outputId": "58e6781c-530a-45d4-bb7a-dfe43f6d9800",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "classifications {\n",
              "  classes {\n",
              "    index: 4\n",
              "    score: 0.45703125\n",
              "    class_name: \"Perca fluviatilis\"\n",
              "  }\n",
              "  head_index: 0\n",
              "}"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run inference\n",
        "image = vision.TensorImage.create_from_file(image_path1)\n",
        "classification_result = classifier.classify(image)\n",
        "classification_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmG5EbJzX9ZT",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "image_path2 = '004b7364-500f-46f7-a06e-4a43feb24d35.png'\n",
        "\n",
        "img = mpimg.imread(image_path2)\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L2OnAiWIHyJ",
        "outputId": "c7132c08-729a-453f-d6e8-4ec84d7567d2",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "classifications {\n",
              "  classes {\n",
              "    index: 2\n",
              "    score: 0.7265625\n",
              "    class_name: \"Esox lucius\"\n",
              "  }\n",
              "  head_index: 0\n",
              "}"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run inference\n",
        "image = vision.TensorImage.create_from_file(image_path2)\n",
        "classification_result = classifier.classify(image)\n",
        "classification_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3hCJAm9VWFC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "image_path3 = '009dd0c2-59f8-42b7-98e8-f272d51e41f1.png'\n",
        "\n",
        "img = mpimg.imread(image_path3)\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tJYPhSYVWIT",
        "outputId": "2725ca07-cc3e-4be2-d1a3-82c0ec1cd045",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "classifications {\n",
              "  classes {\n",
              "    index: 2\n",
              "    score: 0.95703125\n",
              "    class_name: \"Esox lucius\"\n",
              "  }\n",
              "  head_index: 0\n",
              "}"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run inference\n",
        "image = vision.TensorImage.create_from_file(image_path3)\n",
        "classification_result = classifier.classify(image)\n",
        "classification_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhONU-lZVduC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhBU5NCy5Ji2"
      },
      "source": [
        "# Read more\n",
        "\n",
        "You can read the [image classification](https://www.tensorflow.org/lite/examples/image_classification/overview) example to learn technical details. For more information, please refer to:\n",
        "\n",
        "*   TensorFlow Lite Model Maker [guide](https://www.tensorflow.org/lite/guide/model_maker) and [API reference](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker).\n",
        "*   Task Library: [ImageClassifier](https://www.tensorflow.org/lite/inference_with_metadata/task_library/image_classifier) for deployment.\n",
        "*   The end-to-end reference apps: [Android](https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android), [iOS](https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/ios), and [Raspberry PI](https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/raspberry_pi).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc4Jk8TvBQfm"
      },
      "source": [
        "## Customize Post-training quantization on the TensorFLow Lite model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD8BOYrHBiDt"
      },
      "source": [
        "[Post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization) is a conversion technique that can reduce model size and inference latency, while also improving CPU and hardware accelerator inference speed, with a little degradation in model accuracy. Thus, it's widely used to optimize the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyIo0d5TCzE2"
      },
      "source": [
        "Model Maker library applies a default post-training quantization techique when exporting the model. If you want to customize post-training quantization, Model Maker supports multiple post-training quantization options using [QuantizationConfig](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/config/QuantizationConfig) as well. Let's take float16 quantization as an instance. First, define the quantization config."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8hL2mstCxQl",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "config = QuantizationConfig.for_float16()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1gzx_rmFMOA"
      },
      "source": [
        "Then we export the TensorFlow Lite model with such configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTJzFQnJFMjr",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='.', tflite_filename='model_fp16.tflite', quantization_config=config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Safo0e40wKZW"
      },
      "source": [
        "In Colab, you can download the model named `model_fp16.tflite` from the left sidebar, same as the uploading part mentioned above."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "vvIFTOakK2jv",
        "3zR0YiA3JjK5",
        "w-VDriAdsowu"
      ],
      "name": "image_classification",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
